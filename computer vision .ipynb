{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293861d5-cbb4-42a3-9486-4ddfd0b00058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Import Libraries\n",
    "# ----------------------------------------\n",
    "import cv2  # OpenCV for computer vision tasks\n",
    "import numpy as np  # NumPy for numerical operations\n",
    "\n",
    "# ----------------------------------------\n",
    "# Define class labels the model can detect\n",
    "# ----------------------------------------\n",
    "# These are 21 classes (0 = background, not used)\n",
    "CLASSES = [\n",
    "    \"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "    \"sofa\", \"train\", \"tvmonitor\"\n",
    "]\n",
    "\n",
    "# ----------------------------------------\n",
    "# Assign unique RGB colors to each class\n",
    "# Shape: (21, 3)\n",
    "# Each row is a random (R, G, B) color\n",
    "COLORS = np.random.uniform(\n",
    "    low=0,       # Minimum RGB value\n",
    "    high=255,    # Maximum RGB value\n",
    "    size=(len(CLASSES), 3)  # 21 rows × 3 columns for RGB\n",
    ")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Load the Caffe model\n",
    "# ----------------------------------------\n",
    "# - prototxt: defines network architecture\n",
    "# - caffemodel: contains learned weights\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    prototxt=r\"MobileNetSSD_deploy.prototxt\",\n",
    "    caffeModel=r\"MobileNetSSD_deploy.caffemodel\"\n",
    ")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Open webcam stream (device 0 = default webcam)\n",
    "cap = cv2.VideoCapture(0)  # Or you can pass a video file path here\n",
    "\n",
    "# ----------------------------------------\n",
    "# Loop through frames\n",
    "while True:\n",
    "    # Capture frame-by-frame from the webcam\n",
    "    ret, frame = cap.read()  # ret = success flag, frame = current image\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if frame not captured properly\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Create a blob from the image for DNN\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image=cv2.resize(frame, (300, 300)),  # Resize frame to 300x300\n",
    "        scalefactor=1.0 / 127.5,              # Scale pixel values\n",
    "        size=(300, 300),                      # Model's required input size\n",
    "        mean=(127.5, 127.5, 127.5),           # Mean subtraction for normalization\n",
    "        swapRB=False,                         # BGR → RGB conversion flag\n",
    "        crop=False                            # Don't crop image\n",
    "    )\n",
    "\n",
    "    # Pass the blob to the network\n",
    "    net.setInput(blob)  # Sets blob as input to model\n",
    "\n",
    "    # Forward pass to get output detections\n",
    "    detections = net.forward()  # Shape: [1, 1, N, 7]  \n",
    "    # 7 = [batch id, class id, confidence, xmin, ymin, xmax, ymax]\n",
    "    # ----------------------------------------\n",
    "    # Loop through each detection\n",
    "    for i in range(detections.shape[2]):# detections[0, 0, i] = 1 detection\n",
    "        #print(detections)\n",
    "        confidence = detections[0, 0, i, 2]  # Index 2 = confidence (float)\n",
    "\n",
    "        if confidence > 0.5:  # Only consider detections with > 50% confidence\n",
    "\n",
    "            class_index = int(detections[0, 0, i, 1])  # Index 1 = class ID\n",
    "            label = CLASSES[class_index]\n",
    "\n",
    "            # Detection box values are ratios → scale to frame size\n",
    "            box = detections[0, 0, i, 3:7] * np.array([\n",
    "                frame.shape[1],  # Width\n",
    "                frame.shape[0],  # Height\n",
    "                frame.shape[1],  # Width\n",
    "                frame.shape[0]   # Height\n",
    "            ])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")  # Bounding box coords\n",
    "\n",
    "            # ----------------------------------------\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(\n",
    "                img=frame,                           # Image to draw on\n",
    "                pt1=(startX, startY),                # Top-left corner\n",
    "                pt2=(endX, endY),                    # Bottom-right corner\n",
    "                color=COLORS[class_index],           # Color from our list\n",
    "                thickness=2                          # Line thickness\n",
    "            )\n",
    "\n",
    "            # Prepare text label: \"class: confidence\"\n",
    "            label_text = f\"{label}: {confidence:.2f}\"\n",
    "\n",
    "            # Position text slightly above the box if space allows\n",
    "            y = startY - 15 if (startY - 15) > 15 else (startY + 15)\n",
    "\n",
    "            # ----------------------------------------\n",
    "            # Draw the label text above the box\n",
    "            cv2.putText(\n",
    "                img=frame,                          # Frame to draw text on\n",
    "                text=label_text,                    # Label string\n",
    "                org=(startX, y),                    # Bottom-left corner of text\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,  # Font\n",
    "                fontScale=0.5,                      # Font size\n",
    "                color=COLORS[class_index],          # Font color\n",
    "                thickness=2                         # Font thickness\n",
    "            )\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Real-Time Object Detection\", frame)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ----------------------------------------\n",
    "# Cleanup: release the camera and close window\n",
    "cap.release()             # Stop webcam\n",
    "cv2.destroyAllWindows()   # Close all OpenCV windows\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
